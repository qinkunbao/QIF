\section{Introduction}
%% side channels are important
Side channels are inevitable in modern computer systems as the sensitive information 
may be leaked by many kinds of inadvertent behaviors, 
such as power, electromagnetic radiation and even sound~\cite{}. 
Among them, software-based side-channel channels (e.g., cache attacks, memory page attacks,
and controlled-channel attacks) are especially common 
and have been studied for years~\cite{}. 
Those vulnerabilities result from vulnerable software and shared hardware components.
By observing the outputs or hardware behaviors, attackers can
infer the program execution flow that manipulate secrets and 
guess the secrets such as encryption keys~\cite{}.

%% to deal with side channels, we can protect or detect them and detection is better
Various countermeasures have been proposed to defend against 
software-based side-channel attacks. Hardware level solutions, 
including reducing shared resources, adopting oblivious RAM, and using
transnational memory~\cite{182946,203878,217537} need to change the hardware
and modern complex computer systems, which is unpractical and hard to adopt in 
reality. Therefore, a more promising and universal direction are software countermeasures, 
detecting and eliminating side channels vulnerabilities from source code base.

After examing the root cause of many software-based side channels, we believe that
many of them are caused by the fowllowing two specific types of disaster: 
data flow from secrets to load addresses and data flow from secrets to branch conditions.
We call them secret-dependent control-flow and memory-access correspondingly.
Therefore, a central problem is identifying those two code patterns automatically.
Recent works~\cite{203878} adopt static and dynamic analysis
to detect side-channels.
They can find many potential leak sites in real-world software, 
but fail to report how severe a potential leakage could be. 
Many of the reported vulnerabilities are typically hard to exploit
and leak very little information. For example, DATA~\cite{} reports
2246 potential leakage site for the RSA implementation in OpenSSL.
After some inspectations, 1510 are dismissed, but it still
leaves 278 control-flow and 460 data-access patterns. For software
developers, it is hard for them to fix all those vulnerabilities.
While some vulnerabilities can be used to recover the full secret
keys~\cite{}, many other vulnerabilities prove to be less serious in reality.

To assess the sensitive level of side-channel vulnerabilities, we need a proper 
quantification metric.
Static methods, usually with the abstract interpretation, can give a leakage upper bound, 
which is useful to justify the implementation is secure when they report zero leakage. 
However, they cannot indicate how serious the leakage is because of the over-approximation~\cite{}
they make during the analysis. 
For example, CacheAudit~\cite{} reports that the upper bound leakage of AES-128 exceeds 
the original key size. The dynamic methods take another way with a concrete input and 
run the program in real environment. Although they are very precise in term of true leakages, 
no existing tool can precisely assess the vulnerabilities they discover.

To overcome above limitations, we propose a novel method
to quantify information leakage more precisely. 
Different from previous works, which only consider the
``average'' information leakage, we study the problem from real attack scenarios.
The average information assumes that the target program will have \textbf{variable} sensitive 
information when the attacker launches the attack.
However, for real-world attacks, an adversary may run the target problem again and over again 
with \textbf{fixed} unknown sensitive information such as the key. 
Therefore, the previous threat model can't catch real attack scenarios.
In contrast, our method is more precise and fine-grained. 
We quantify the amount of leaked information as the cardinality of the set of possible inputs 
based on attackers' observations. 

Before an attack, an adversary has a big but finite input space.
Every time when the adversary observes one leakage site, he can eliminate some 
potential inputs and reduce the size of the input space. 
The smaller the input space is, the more information is actually gained. 
In extreme cases, if the size of the input space reduces to one, 
the adversary can determine the input information uniquely, which means all information
(e.g., the whole secret key) is leaked. By counting the number of different input, 
we can quantify the information leakage more precisely.

More specifically, we build a tool called \tool{},\footnote{Clever Hans is a horse that can ``count''.
Our tool uses an advanced method to count the number of leaked bits through side channel.}
which could discover and estimate those potential information leakage sites 
as well as how many bits they can leak. 
We assume that adversaries can exploit different control-flow transfers and data-access patterns when 
the program processes different sensitive data. 
%We refer them as the potential information leakage sites. 
First, we collect the dynamic execution trace for each input of the target libraries 
and then run symbolic execution on the traces. 
In this way, we model each side-channel leakage as a math formula. 
The sensitive input is divided into several independent bytes and each byte is regarded as 
a unique symbol. Those formulas can precisely model every the side-channel vulnerability.
Then we extend the problem to multiple leakages and related leakages
and introduce a monte carlo sampling method to estimate the total information leakage.
In fact, if the application has a different sensitive input but still satisfies the formula, 
the code can still leak the same information. 


%Based on the fixed attack target, we classify the software-based side-channel 
%vulnerabilities into two categories: 1.\textit{secret-dependent control-flow transfers} 
%and 2.\textit{secret-dependent data accesses} and model them with math formulas which
%constrain the value of sensitive information.
%We quantify the amount of leaked information as the number of possible solutions that are
%reduced after applying each constrains.


%Our method can identify and quantify address-based
%sensitive information leakage sites in real-world applications automatically. 
%Adversaries can exploit different control-flow transfers and data-access patterns when 
%the program processes different sensitive data. We refer them as the potential information
%leakage sites. Our tool can discover and estimate those potential information leakage sites 
%as well as how many bits they can leak. We are also able to report precisely how many bits
%can be leaked in total if an attacker observes more than one site.
%We run symbolic execution on execution traces. We model each side-channel leakage as a math formula. 
%The sensitive input is divided into several independent bytes and each byte is regarded as 
%a unique symbol. Those formulas can precisely model every the side-channel vulnerability. 
%In other words, if the application has a different sensitive input but still satisfies the formula, 
%the code can still leak the same information.  
%Those information leakage sites may spread in the whole program 
%and their leakages may not be dependent. Simply adding them up can only get a coarse upper bound 
%estimate. In order to accurately calculate the total information leakage, we must know the 
%dependent relationships among those multiple leakages sites. Therefore, we introduce a 
%monte carlo sampling method to estimate the total information leakage.

We apply \tool{} on several crypto and non-crypto libraries including OpenSSL,
MbedTLS and libjpeg. The experiment result confirms that \tool{} can precisely identify the pre-known vulnerabilities,
reports how much information is leaked and which byte in the original sensitive buffer is leaked. 
Although some of the analyzed crypto libraries have a number of side-channels, they actually
leak very little information. Also, we also use the tool to analysis the two reported side-channel attack 
in the libjpeg library. Finally, we present new vulnerabilities. With the help of \tool{}, we confirm those
vulnerabilities are easily to be exploited. Our results are superisingly different compared to previous results
and much more useful in practice.

In summary, we make the following contributions:

\begin{itemize}
	\item We propose a novel method that can quantify fine-grained side-channel
        information leakages. We model each information leakage vulnerability as math formulas and 
        mutiple side-channel vulnerabilities can be seen as the disjunctions of those formulas, which
        precisely models the program semantics.
        \item We transfer the information quantification problem into a probabilty distribution problem and 
        use the Monte Carlo sampling method to estimate the information leakage. Some initial results indicate the 
        the sampling method suffers from the curse of dimensionality problem. We therefore design a guided
        sampling method and provide the corresponding error esitimate.
	\item We implement the proposed method into a practical tool and apply it on several real-world software. \tool{} 
        successfully identify the address-based side-channel vulnerabilities and provide the corresponding
        information leakge. The information lekage result provide the detailed information that help developers
        to fix the vulnerability.
\end{itemize}



