\section{Introduction}
%% side channels are important
Side channels are hardly avoided in modern computer systems as the sensitive information 
may be leaked by kinds of neglected behaviors, 
such as power, electromagnetic radiation and even sound~\cite{}. 
Among them, software-based side-channel vulnerabilities are especially common and have been studied for years~\cite{}. 
The vulnerability results from vulnerable software codes and shared hardware components.
As the threat model in Figure~\ref{}, there is an information flow with secrets.  
By observing the outputs or hardware behaviors, attackers could 
infer the program execution and guess the secrets such as encryption keys~\cite{}.

%% to deal with side channels, we can protect or detect them and detection is better
Various countermeasures have been proposed to defend against 
software-based side-channel attacks by reducing the shared resources
and eliminating the leak paths~\cite{182946,203878,217537}. 
In addition to runtime overheads, they are limited to specific hardwares. 
So it is imperative to discover and fix side channel vulnerabilities in advance 
and automatic detection methods are proposed recently~\cite{}.

%% There are some detection methods but need a good assess method 
In general, both static analysis and dynamic analysis
can be used to detect software-based side-channel vulnerabilities.
Statically, XXXXXX. And dynamically, XXXXX.
These works help to find a list of hidden vulnerabilities in real-world softwares, 
but fail to report how severe a potential leakage site could be. 
Many of the reported vulnerabilities are typically hard to be exploited 
and leak very little information (e.g., one bit of the length of the key~\cite{203878}).  
For example, the vulnerabilities in OpenSSL library are assigned with low severity and not considered 
in the threat model now~\cite{https://www.openssl.org/policies/secpolicy.html}. 
It is worthwhile to have a tool to tell how much information is actually leaked and help to fix them.

To assess side-channel vulnerabilities, the first problem is that we need a proper quantification metric .
Although tools based on static analysis with abstract interpretation can give an upper bound, 
which is useful to justify whether the implementation is secure enough, 
they can’t indicate the leakage is seuvere or not due to the over-approximation~\cite{}. 
The dynamic methods will take a concrete input and run the program actually, which should be very precise in term of real leakage,
but they suffer from the incompleteness of testing and trade-off of performance and accuracy~\cite{}. 
%For example, DATA~\cite{217537} reports more than 2000 potential leakage sites for the RSA implementation of OpenSSL.
%But most of them were dismissed by the author after some manual inspections.

Secondly, open source libraries may have multiple leakage sites, which can be exploited for attackers
at one time~\cite{191010,7163052,hornby2011side}. 
%The attacker may retrieve part of the sensitive information from one site, part of the sensitive
%information from another site and combine them.
It is necessary to know how much information is actually leaked in total. 
No existing tools can practically estimate the total information leakage from multiple leakage sites in real-world libraries.
Simply adding the results together gets a very rough upper bound of the total information leakage if those 
leakages aren’t independent. 


To overcome the above limitations, we propose a novel method
to more precisely quantify the information leakage. Previous work only considers the
``average'' information leakage which often neglects severe scenarios.
The average information assumes that the target program will have \textbf{different} sensitive 
information as the input when the attacker launches the attack,
which often does not match the attack scenario. During the real side-channel
attacks, an adversary may run the target problem again and over again with the 
fixed unknown sensitive information as the input. Therefore, the previous
threat model can't catch real attack scenarios.

In contrast, our method is more precise and fine-grained. 
For our analysis, the input key is fixed. We classify the address-based side-channel 
vulnerabilities into two categories: 1.\textit{secret-dependent control-flow transfers} 
and 2.\textit{secret-dependent data access} and model them with the math formulas which
constrain the value of sensitive information.
We define the amount of leaked information as the number of possible solutions that can
reduced after applying each constrains.
It is interesting to mention that the definition is different from the 
definition in previous static-based analysis tools. 
Before the attack, the adversary has a big but finite input space.
Every time the adversary observes one leakage site, he can eliminate some potential input and
reduce the size of the input space. The smaller the input space is, the more information is 
actually gained. On an extreme situation, if the size of the input space reduces to one, the
adversary can determine the input information uniquely, which means the total information is 
leaked. We define the leaked information as the proportion of the number of possible input 
that satisfies the attacker's observation.

Our method can identify and quantify address-based
sensitive information leakage sites in real-world applications automatically. 
Adversaries can exploit different control-flow transfers and data-access patterns when 
the program processes different sensitive data. We refer them as the potential information
leakage sites. Our tool can discover and estimate those potential information leakage sites 
as well as how many bits they can leak. We are also able to report precisely how many bits
can be leaked in total if an attacker observes more than one site.
We run symbolic execution on execution traces. We model each side-channel leakage as a math formula. 
The sensitive input is divided into several independent bytes and each byte is regarded as 
a unique symbol. Those formulas can precisely model every the side-channel vulnerability. 
In other words, if the application has a different sensitive input but still satisfies the formula, 
the code can still leak the same information.  
Those information leakage sites may spread in the whole program 
and their leakages may not be dependent. Simply adding them up can only get a coarse upper bound 
estimate. In order to accurately calculate the total information leakage, we must know the 
dependent relationships among those multiple leakages sites. Therefore, we introduce a 
monte carlo sampling method to estimate the total information leakage.

We implement the proposed method as a tool named \tool{} which can precisely discover and quantify the leaked information. 
We apply \tool{} on several crypto and non-crypto libraries including OpenSSL,
MbedTLS and libjpeg. The experiment result confirms that \tool{} can precisely identify the pre-known vulnerabilities,
reports how much information is leaked and which byte in the original sensitive buffer is leaked. 
The result shows that while those crypto libraries have a number of side-channels, most of them actually
leak very little information. Also, we also use the tool to analysis the two reported side-channel attack 
in the libjpeg library. Finally, we present new vulnerabilities. With the help of \tool{}, we confirm those
vulnerabilities are easily to be exploited. Our results are superisingly different compared to previous results
and much more useful in practice.

In summary, we make the following contributions:

\begin{itemize}
	\item We propose a novel method that can quantify fine-grained side-channel
        information leakages. We model each information leakage vulnerability as math formulas and 
        mutiple side-channel vulnerabilities can be seen as the disjunctions of those formulas, which
        precisely models the program semantics.
        \item We transfer the information quantification problem into a probabilty distribution problem and 
        use the Monte Carlo sampling method to estimate the information leakage. Some initial results indicate the 
        the sampling method suffers from the curse of dimensionality problem. We therefore design a guided
        sampling method and provide the corresponding error esitimate.
	\item We implement the proposed method into a practical tool and apply it on several real-world software. \tool{} 
        successfully identify the address-based side-channel vulnerabilities and provide the corresponding
        information leakge. The information lekage result provide the detailed information that help developers
        to fix the vulnerability.
\end{itemize}



