\section{Background}
In this section, we first present a basic introduction to the 
memory-based side-channel attacks. Those attacks 
are what we attempt to study in the paper. After that, we 
will show existing methods on side-channel detections and quantifications.

\subsection{Address-based Side-Channels}
Address-based side-channels are information channels that can 
leak sensitive information unintendedly through different 
behaviors when the program accesses different memory addresses. 
Fundamentally, those differences were caused by the memory hierarchy design 
in modern computer systems. When the CPU fetches the data, it first searches
the cache, which stores copies of the data that was 
frequently used in main memory. If the data doesn't exist in the cache, 
the CPU will read the data from the main memory (RAM). 
According to the layer that causes the side-channels, we classify
the address-based side channels into two categories: 
cache-based side-channel attacks and memory-based side-channel attacks.

\subsubsection{Cache-based Attacks}
In general, the cached-based side-channels seek 
information relying on the time differences between the cache miss
and the cache hit. Here we introduce two frequently used cache attacks:
PRIME+PROBE, FLUSH+RELOAD.

\textit{PRIME+PROBE} targets a single cache set. It has two phases. During the
``prime'' phase, the attacker fills the cache set with his data.
In the second ``probe'' phase, the attacker reaccesses the cache set
again. If the victim accesses the cache set and evicts part of 
the data, the attacker will experience a slow measurement. If not, 
the measurement will be fast. By knowing which cache set the target
program that accesses, the attacker can infer part of
the sensitive information.

\textit{FLUSH+RELOAD} targets a single cache line. 
It requires the attacker and victim share the same memory.
It also has two phases. During the "flush" stage, the attacker 
flushes the ``monitered memory'' from the cache. Then the attacker
waits for the victim to access the memory. In the next phase, the 
attacker reload the ``monitored memory''. If the time is short, which
indicates there is a cache hit and the victim reloads the memory before. 
On the other hand, the time will be longer since the CPU need to reload
the memory into the cache line. 

\subsubsection{Memory-based Attack}
Memory-based side-channel attack~\cite{7163052} exploits the different behaviors when the
program accesses different page tables. For example, the controlled-channel attack~\cite{7163052},
which works in the kernel space, can infer the sensitive data in the shielding systems by
observing the page fault sequences after restricting some code and
data pages. 

After examing the memory-based side-channels attack. We believe the root
cause of those attacks are secret-dependent memory access and control
flow transfers.

\lstinputlisting[language=c, 
                 numbers=left,
                 caption={Sample code shows secret-dependent memory access and 
                          secret-dependent control-flow transfer.},
                 captionpos=b,
                 label={code:background},
                 frame=single,
                 basicstyle=\fontsize{7}{9}\selectfont\ttfamily]
                 {sample_code/background.c}

For example, the above code~\ref{code:background} show a simple encryption function that
has the two kinds of side-channels. At line 11, depending on the value of a key,
the code will access the different entry in the predefined table. At the
line 13, the code will do a series of computation and determine if the code in the if
branch is executed or not. Such vulnerabilities are called the memory-based 
side-channles. We identify and quantify the leakage of the two kinds of vulnerabilities 
in the paper.

\subsection{Information Leakage Quantification}
Given an event $e$ which occurs with the probability $P(e)$, if the event $e$ happens, 
then we receive
\begin{displaymath}
    I = - \log_2P(e)
\end{displaymath}
bits of information by knowing the event $e$.
Consider a char variable $a$ in a C program, which has the size
of one byte (8 bits). It ranges from 0 -- 255.  Assume
 \textit{a} has the uniform distribution. If at one time we observe that $a$
equals $1$, the probability of this observation is $\frac{1}{256}$. So the information we get is 
$-\log(\frac{1}{256}) = 8$ bits, which is exactly the size of the char variable in the C program.

Existing works on information leakage quantification are based on mutual information or 
min-entropy \cite{10.1007/978-3-642-00596-1_21}.
In their frameworks, the input sensitive
information $K$ is viewed as a random variable. Let $k_i$ be one of the possible
value of $K$. The Shannon entropy $H(K)$ is defined by
\begin{displaymath}
    H(K) = - \sum_{k_i {\in} K}P(k_i)\log_2P(k_i)
\end{displaymath}

The Shannon entropy can be used to quantify the initial uncertainty about the sensitive
information. Suppose a program ($P$) with the $K$ as
the sensitive input, an adversary has some observations (O) through the side-channels.
In this work, the observations are referred as the secret-dependent control-flows and
secret-dependent data-access patterns. The conditional entropy $H(K|O)$ is
\begin{displaymath}
    H(K|O) = - \sum_{o_j {\in} O} {P(o_j) \sum_{k_i {\in} K}{P(k_i|o_j)\log_2P(k_i|o_j)}}
\end{displaymath}
Intuitively, the conditional information marks the uncertainty about $K$ after the adversary
has gained some observations (O). 

Many previous works use the mutual information $I(K; O)$ to quantify the leakage which is defined 
as follows:
\begin{displaymath}
    \mathit{Leakage} = I(K;O) = \sum_{k_i {\in} K}{\sum_{o_j {\in} O}{P(k_i, o_j)\log_2\frac{P(k_i, o_j)}{P(k_i)P(o_j)}}}
\end{displaymath}
where $P(k_i, o_i)$ is the joint discrete distribution of $K$ and $O$.
Alternatively, the mutual information can also be computed with the following equation:
\begin{displaymath}
    \mathit{Leakage} = I(K;O) = H(K) - H(K|O) = H(O) - H(O|K)
\end{displaymath}

For a deterministic program, once the input $K$ is fixed, the program will have the same
control-flow transfers and data-access patterns. As a result, $P(k_i, o_j)$ will always
equals to 1 or 0. So the conditional entropy $H(O|K)$ will equal to zero. So the leakage defined
by the mutual information can be simplified into:
\begin{displaymath}
\label{mutual:information}
    \mathit{Leakage} = I(K;O) = H(O)
\end{displaymath}
In other words, once we know the distribution of those memory-access patterns. We can 
calculate how much information is actually leaked.

Another common method is based on the maximal leakage~\cite{10.1007/978-3-642-00596-1_21,10.1007/978-3-642-31424-7_40,182946}.
The formal information theory can prove that the maximal leakage is the upper bound of the mutual 
information (Channel Capacity).

\begin{displaymath}
    \mathit{Leakage} = \log(C(O))
\end{displaymath}
$C(O)$ represents the number of different observations that an attacker can have. 

Now we provide a concrete example to show how the two types of quantification definition works.


\textbf{Maximal leakage} 
Depending on the value of key, the code can run four different branches which corrosponding to 
four different observations. Therefore, by the maximal leakage definition, the leakage equals to 
$\log4 = 2$ bits.

\lstinputlisting[language=c, 
                 numbers=left,
                 caption={A simple program},
                 captionpos=b,
                 frame=single,
                 label={code::entropy},
                 basicstyle=\fontsize{7}{9}\selectfont\ttfamily]
                 {sample_code/dependent.c}

\textbf{Mutual Information} If the key satisfies the uniform distribution, the probability of the code runs each branch
can be computed with the following result: 
\begin{table}[h]
\centering
\resizebox{\columnwidth}{!}{
\begin{tabular}{|c|c|c|c|c|}
\hline
Branch & A     & B      & C      & D       \\ \hline
Possibility      & 1/256 & 64/256 & 64/256 & 127/256 \\ \hline
\end{tabular}
}
\caption{The distribution of observations}
\end{table}
Therefore, the leakage equals to 
$\frac{1}{256}\log\frac{1}{256} + \frac{1}{4}\log\frac{1}{4}*2 + \frac{127}{256}\log\frac{127}{256} = 1.7$ bits.

