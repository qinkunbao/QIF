\section{Background}
In this section, we first present a basic introduction to the 
software-based side-channel attacks. Those attacks 
are what we attempt to study in the paper. After that, we 
will show existing methods on side-channel detection and quantification.

\subsection{Software-based Side-Channels}
Software-based side-channels % are information channels that can 
leaks sensitive information unconsciously through different 
behaviors. %when the program accesses different memory addresses. 
Fundamentally, those differences were caused by the memory hierarchy design 
in modern computer systems. When the CPU fetches the data, it first searches
the cache, which stores copies of the data that was 
frequently used in main memory. If the data doesn't exist in the cache, 
the CPU will read the data from the main memory (RAM). 
According to the layer that causes the side-channels, we classify
the software-based side channels into two categories: 
cache-based side-channel attacks and memory-based side-channel attacks.

\subsubsection{Cache-based Attacks}
In general, the cached-based side-channels seek 
information relying on the time differences between the cache miss
and the cache hit. Here we introduce two frequently used cache attacks:
PRIME+PROBE and FLUSH+RELOAD.

\textit{PRIME+PROBE} targets a single cache set. It has two phases. During the
``prime'' phase, the attacker fills the cache set with his data.
In the second ``probe'' phase, the attacker re-accesses the cache set
again. If the victim accesses the cache set and evicts part of 
the data, the attacker will experience a slow measurement. If not, 
it will be fast. By knowing which cache set the target
program that accesses, the attacker can infer parts of
the sensitive information.

\textit{FLUSH+RELOAD} targets a single cache line. 
It requires the attacker and victim share the same memory.
It also has two phases. During the ``flush'' stage, the attacker 
flushes the ``monitored memory'' from the cache. Then the attacker
waits for the victim to access the memory. In the next phase, the 
attacker reload the ``monitored memory''. If the time is short, which
indicates there is a cache hit and the victim reloads the memory before. 
On the other hand, the time will be longer since the CPU need to reload
the memory into the cache line. 

\subsubsection{Memory-based Attack}
Memory-based side-channel attack~\cite{7163052} exploits the different behaviors when the
program accesses different page tables. For example, the controlled-channel attack~\cite{7163052},
which works in the kernel space, can infer the sensitive data in the shielding systems by
observing the page fault sequences after restricting some code and
data pages. 

After examining the memory-based side-channels attack, we believe the root
cause of those attacks are secret-dependent memory access and control
flow transfers.  \fixme{This paragraph is confusing. Secret-dependent memory access and control
  flow transfers can be cache-based side channels. We need further develop this so it is not a surprise
when it is mentioned in the next subsection.}

%
%\lstinputlisting[language=c, 
%                 numbers=left,
%                 caption={Sample code shows secret-dependent memory access and 
%                          secret-dependent control-flow transfer.},
%                 captionpos=b,
%                 label={code:background},
%                 frame=single,
%                 basicstyle=\fontsize{7}{9}\selectfont\ttfamily]
%                 {sample_code/background.c}

%For example, the above code~\ref{code:background} show a simple encryption function that
%has the two kinds of side-channels. At line 11, depending on the value of a key,
%the code will access the different entry in the predefined table. At the
%line 13, the code will do a series of computation and determine if the code in the if
%branch is executed or not. Such vulnerabilities are called the memory-based 
%side-channles. We identify and quantify the leakage of the two kinds of vulnerabilities 
%in the paper.

\subsection{Information Leakage Quantification}

\fixme{Clarify mutual information, min-entropy, and maximal leakage. How many types?}

Given an event $e$ which occurs with the probability $P(e)$, if the event $e$ happens, 
then we receive
\begin{displaymath}
    I = - \log_2P(e)
\end{displaymath}
bits of information by knowing the event $e$.
Consider a char variable $a$ in a C program, which has the size
of one byte (8 bits). It ranges from 0 -- 255.  Assume
 \textit{a} has the uniform distribution. If at one time we observe that $a$
equals $1$, the probability of this observation is $\frac{1}{256}$. So the information we get is 
$-\log(\frac{1}{256}) = 8$ bits, which is exactly the size of the char variable in the C program.

Some existing work on information leakage quantification is based on mutual information or 
min-entropy \cite{10.1007/978-3-642-00596-1_21}.
In these frameworks, the input sensitive
information $K$ is viewed as a random variable. Let $k_i$ be one of the possible
value of $K$. The Shannon entropy $H(K)$ is defined as
\begin{displaymath}
    H(K) = - \sum_{k_i {\in} K}P(k_i)\log_2P(k_i)
\end{displaymath}

The Shannon entropy can be used to quantify the initial uncertainty about the sensitive
information. Suppose a program with some
sensitive input $K$, an adversary has some observations ($O$) through some side channel.
In this work, the observations are referred as the secret-dependent control-flows and
secret-dependent data-access patterns. \fixme{See the comment above, we need to explain these
  patterns before this point.} The conditional entropy $H(K|O)$ is
\begin{displaymath}
    H(K|O) = - \sum_{o_j {\in} O} {P(o_j) \sum_{k_i {\in} K}{P(k_i|o_j)\log_2P(k_i|o_j)}}
\end{displaymath}
Intuitively, the conditional information marks the uncertainty about $K$ after the adversary
has gained some observations ($O$). 

Some previous work uses the mutual information $I(K; O)$ to quantify the leakage which is defined 
as follows:
\begin{displaymath}
    \mathit{Leakage} = I(K;O) = \sum_{k_i {\in} K}{\sum_{o_j {\in} O}{P(k_i, o_j)\log_2\frac{P(k_i, o_j)}{P(k_i)P(o_j)}}}
\end{displaymath}
where $P(k_i, o_i)$ is the joint discrete distribution of $K$ and $O$.
Alternatively, the mutual information can also be computed with the following equation:
\begin{displaymath}
    \mathit{Leakage} = I(K;O) = H(K) - H(K|O) = H(O) - H(O|K)
\end{displaymath}

For a deterministic program, once the input $K$ is fixed, the program will have the same
control-flow transfers and data-access patterns. As a result, $P(k_i, o_j)$ will always
equals to 1 or 0. So the conditional entropy $H(O|K)$ will equal to zero. So the leakage defined
by the mutual information can be simplified into:
\begin{displaymath}
\label{mutual:information}
    \mathit{Leakage} = I(K;O) = H(O)
\end{displaymath}
In other words, once we know the distribution of those memory-access patterns. We can 
calculate how much information is actually leaked.

Another common method is based on the maximal leakage~\cite{10.1007/978-3-642-00596-1_21,10.1007/978-3-642-31424-7_40,182946}.
The formal information theory can prove that the maximal leakage is the upper bound of the mutual 
information (Channel Capacity).

\begin{displaymath}
    \mathit{Leakage} = \log(C(O))
\end{displaymath}
Here $C(O)$ represents the number of different observations that an attacker can have. 


\section{Running Example}

Now we provide a concrete example to show how the two types of quantification definition works and show that
how our method is different.

\vspace{3pt}
\textbf{Maximal Leakage.} 
Depending on the value of key, the code can run four different branches which corrosponding to 
four different observations. Therefore, by the maximal leakage definition, the leakage equals to 
$\log4 = 2$ bits.

\lstinputlisting[language=c, 
                 numbers=left,
                 caption={A simple program},
                 captionpos=b,
                 frame=single,
                 label={code::entropy},
                 basicstyle=\fontsize{7}{9}\selectfont\ttfamily]
                 {sample_code/dependent.c}

\vspace{3pt}
\textbf{Mutual Information.}
If the key satisfies the uniform distribution, the probability of the code runs each branch
can be computed with the following result.  

\begin{table}[h]
\centering
\resizebox{\columnwidth}{!}{
\begin{tabular}{|c|c|c|c|c|}
\hline
Branch & A     & B      & C      & D       \\ \hline
Possibility      & 1/256 & 64/256 & 64/256 & 127/256 \\ \hline
\end{tabular}
}
\caption{The distribution of observations}
\end{table}

Therefore, the leakage equals to 
$\frac{1}{256}\log\frac{1}{256} + \frac{1}{4}\log\frac{1}{4}*2 + \frac{127}{256}\log\frac{127}{256} = 1.7$ bits.

\vspace{3pt}
\textbf{\tool.}
\fixme{What is out result here?}
