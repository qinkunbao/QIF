\section{Motivation}
\subsection{Techinical Chanllenges}
In this section, we articulate several chanllenges and existing problems
in quantifying the side-channel vulnerability leakages. We briefly describe the
chanllenges and then present the corresponding solutions.

\subsubsection{Information Leakage Definition}
Existing static-based side-channel quantification works defined information leakage
as the mutual information or the max leakage. Those definitions provide strong security guarantee
when trying to show a program is secure if the their methods say the program leaks zero bits of
information.
However, the above definition is less useful when if the program has some leakages. 
Considering the example in section ~\ref{code::entropy}, if an attacker observes the
code runs branch A, the attacker can know the key actually equals to 128. Suppose it is 
a dummy password checker, in which case the attacker can fully retrieve the password.

The problem with the existing method is that they are static based. 

We want to have a way that can 
very precisely estimate how much information are leaked for each execution. 
Apparently,the existing method fails to achieve our requirement.
Suppose an attacker can observe which branch the program executes (e.g., flush reload, controlled attack), 
the above code may leak different amount of information depending on the value of input.
For example, if the attacker knows the code executes the branch 0, 
then he will know the key equals 11*2 = 22. 
As the key has 4 bits information in total, we think the amount of information leakage here is 4 bits. 
On the other hand, if the code executes the branch 2, 
the only thing that an attacker can know is that the key doesn’t equal 22, 
which leaks very little information in this case.  

Solution: We model each leakage as one unique formula. 
We come to the original information content definition and use the probability to
mark the information leakage.   

\subsection{Multiple Leakage Sites}
Real-world software usually can have multiple side-channel vulnerabilities. Those vulnerabilities 
may spread in the whole program. An adversary may exploit more than one side-channel vulnerabilities 
to achieve the attack. For example, the controled-side channel attack \cite{7163052} \cite{191010}, the author 
demonstrate an attack against a popular spell checking tool, Hunspell. By observing four sets 
of secret-dependent memory accesses sites in two functions $HashMgr::addword$ and $HashMgr::lookup$, 
the author can recover the word that Hunspell checks.

For the Hunspell, the attacker manually study the source code of Hunspell, figure out
the relation of those vulnerabilities and launch the attack. In order to precisely quantify the
total information leakage, we need to know the relation of those leakage sites. 

Suppose one program have two side-channel vulnerabilities A and B, which leaks $L_A$ and $L_A$ bits
during the exectution. The total information leakage is noted as $L_{Total}$. The relation between
A and B has the following two cases.

\subsubsection{Independent Leakages}
If A and B are independent leakages, the total information leakage will be:
\begin{equation}
\label{independent leakage}
    L_{total} = L_A + L_B
\end{equation} 

\subsubsection{Dependent Leakages}
If A and B are dependent leakages, the total information leakage will be:
\begin{equation}
\label{dependent leakage}
    \max{\{L_A, L_B\}}  <= L_{total} < L_A + L_B
\end{equation}

\subsection{Scalability}



We use the mutual information (MI) to quantify the information leakages. 
For a program P with sensitive information K as the input, the attacker may have some observations O during the execution. 
The information leakage is defined as the mutual information I(O; K) between O and K.
\begin{equation}
I(O; K) = H(O) - H(O|K)
\end{equation}

I(O; K) represent how much uncertainty about K can be reduced if the attacker has the observation O.
For a deterministic program, the program will have the same memory access behavior as long as the input is fixed. 
As the observation of the attacker correlate to the memory access behavior, 
we can have the following formula.
\begin{equation}
O = f(K)
\end{equation}

The function f is determined by the program P. For our project, we can calculate the function f via symbolic execution.
\begin{equation}
I(O; K) = H(O) - H(f(K)|K) = H(O) = H(f(K))
\end{equation}

So the mutual information between O and S equals to the self information of O. 
\begin{equation}
H(O) = Σp(Oi)log(p(Oi))
\end{equation}

For a determinist program, we can calculate the distribution of O as long as we know the distribution of input K. So we can calculate how much information is leaked.

For examples, given a program P, we have the sensitive input K. The K should be a value in a memory cell or a sequential buffer (e.g., an array). We use ki to denote the sensitive information, where i is the index of the byte in the original buffer.  We can have the following equations. The t1, t2, t3, is the temporary values during the execution.
\begin{equation}
t_1 = f1(k1, k2, k3 ... kn)\\
t_2 = f2(k1, k2, k3 ... kn)\\
t_3 = f3(k1, k2, k3 ... kn)\\
tm = fm(k1, k2, k3 ... kn)
\end{equation}

The attacker can retrieve the sensitive information by observing the different patterns in control-flows and data access when the program process different sensitive information. We refer them as the secret-dependent control flow and secret-dependent data access accordingly.

\subsection{Secret-dependent Control Flow}
Here is an example of the secret-dependent control-flows. Consider the code snippet in List 1. Here the key is the confidential data. The code will have different behaviours (time, cache access) dependenting on which branch is actually executing. By observing the behaviour, the attacker can infer which branch actually executed and know some of the sensitive information. One of the famous leakage example is the square and multiply in many RSA implementations. 

For example, the attacker knows the key equals to zero if he observes the code run the branch1. Because key has 256 different possibilities. The original key has lg256 = 8 bits information. If the attacker can observe the code run branch 1. Then he will knows the key equals to zero. If the code run branch 2, the attacker can infer the key doesn’t equal to zero. 

Branch 1
temp = 0xb;
0 =< key <= 256;
temp = key/2;

Information Leakage = -log(1/p) = -log(1/256) = 8 bits

Branch 2
temp != 0; 
0 =< key <= 256;
temp = key/2;

Information Leakage = -log(255/256) bits

\subsection{Seret-dependent Memory Access}

\begin{lstlisting}

T[64]; // Lookup tables with 64 entries
index = key % 63;
temp = T[index]; 
// Secret-dependent memory access       

\end{lstlisting}

The simple program above is an example of secret dependent memory access. Here T is a precomputed tables with sixty-four entries. Depending on the values of key, the program may access any values in the array. Those kind of code patterns may wildly exist in many crypto and media libraries. 

Suppose the attackers observe the code accesses the first entry of the lookup tables. We can have the following formulas.

key mod 63 ≡ 1
0 =< key <= 256

So the key can be one of the following values:
1 64 127 190 253

Information leakages = -log(5/256) =  5.6 bits

