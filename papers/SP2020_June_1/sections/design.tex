%\section{Design}
\section{Design and Implementation}
In this section, we describe the design of \tool{} by focusing on
how our design solves the three challenges discussed in the previous
section.

\subsection{Workflow}
%\subsection{Overview}
The shortcomings of the existing work inspire us to design a new tool to detect
and quantify information leakage vulnerabilities in binaries. The tool has three
steps. First, we run the target program with the concrete input 
(sensitive information) under the dynamic binary instrumentation (DBI) frameworks
to collect the execution traces. After that, we run the symbolic execution 
to capture the fined-grained semantic information of each secret-dependent 
control-flow transfers and data-accesses. 
Finally we run Monte Carlo (MC) to estimate the 
information leakage. 

\begin{figure*}[ht]
    \centering
    \includegraphics[width=0.8\textwidth]{./figures/workflow.pdf}
    \caption{The workflow of \tool{}.}
    \label{fig:Test}
\end{figure*}

\begin{enumerate}
    \item \emph{Execution trace generation.} The design goal of \tool\ is to
    estimate the information leakage as precisely as possible. Therefore,
    we sacrifice the soundness for the precision in terms of program analysis.
    Previous works~\cite{203878,217537} have demonstrated the effectiveness of the
    dynamic program analysis. We run the target binary under the dynamic binary
    instrumentation (DBI) to record the execution trace and the runtime information.
    \item \emph{Instruction level symbolic execution.} We model the 
    attacker's observation about the side-channel vulnerabilities with math
    formula. Each formula capture the fined-grained information between the input secrets
    and the leakage site. For the consideration of precision and performance, 
    we remove the intermediate language(IR) layer of the symbolic execution. 
    Also, the engine only symbolically execute the instruction that might be affected the
    input key. The above design significantly reduces the overhead of the symbolic
    execution, which make the tool scales to real-world programs.
    \item \emph{Leakage estimation.} We transfer the information leakage quantification
    problem into the problem of counting the number of assignments that satisfy the formulas
    which models the observations from attacker. We propose a markov monte carlo method to 
    estimate the number of satisfied solutions. With the help of Chebyshev's Inequality,
    we also give the an error estimate with the probability.
\end{enumerate}


\subsection{Trace Logging}
The trace information can be logged via some emulators (e.g., QEMU) or 
dynamic binary instrumentation tools (DBI). 
We run a program with the concrete input under the DBI to record the
execution trace.
The trace data has the following information:
\begin{itemize}
    \item Each instruction mnemonics and its memory address.
    \item The operands of each instruction and their concrete values during the 
          runtime.
    \item The value of eflags register. 
    \item The memory address and the length of the sensitive information.
     Most software developers stores sensitive information in an array,
     a variable or a buffer, which means that those data is stored in a contiguous 
     area in the memory. We use the symbol information in the binary to track the 
     address in the memory.
\end{itemize}

\subsection{Instruction Level Symbolic Execution}
\label{InstructionSE}
The main purpose of the step is to generate 
constraints of the input sensitive information from the execution trace. 
If we give the target program a new input which 
is different from the origin input that was used 
to generate the execution trace but still satisfies those constraints,
the new execution trace still have the same control flow and 
data access patterns. 

The tool runs the symbolic execution on top of the execution traces.
At the beginning of the symbolic execution, the tool creates fresh 
symbols for each byte in the sensitive buffer. For other data in the 
register or memory at the beginning, we use concrete values from the 
runtime information collected during the runtime. 
During the symbolic execution for each instruction, 
the tool updates every variable in the memory and registers with a
math formula. The formula is made up with concrete values and 
the input key as the symbols accumulated through the symbolic execution.
For each formula, the tool will check weather it can be reduced
into a concrete values (e.g., $k_1+12-k_1 = 12$ ). 
If so, the tool will only use the concrete values in the 
following symbolic execution.

\subsubsection{Verification and Optimization}
We run the symbolic execution (SE) on top of x86 instructions.
In other words, we don't rely on any intermediate languages to 
simplify the implemetation of symbolic execution. 
While the implementation itself 
has a lot of benefits (Better performance, accurate memory model), 
we need to implement the symbolic execution 
rules for each X86 instruction. 
However, due to the complexity of X86, it is inevitable to make mistakes. 
Therefore, we verify the correctness of the SE engine during the execution. 
The tool will collect the runtime information (Register values, 
memory values) and compare them with the formula generated from the 
symbolic execution. Whenever the tool finishes the symbolic execution 
of each instruction, the tool will compare the formula for each symbol 
and its actual value. If the two values don't match, we check the code
and fix the error. Also, if the formula doesn't contain any symbols,
the tool will use the concrete value instead of symbolic execution.

\subsubsection{Secret-dependent control-flows}
An adversary can infer sensitive information from secret dependent control-flows. 
There are two kinds of control-transfer instructions: the unconditional 
control-transfer instructions and the conditional transfer instructions.
The unconditional instructions, like CALL, JUMP, RET transfer control
from one code segment location to another. Since the transfer is 
independent from the input sensitive information, an attacker was 
not able to infer any sensitive information from the control-flow. 
So the unconditional control-transfer doesn't leak any information 
based on our threat model. During the symbolic execution, 
we just update the register information and memory cells with 
new formulas accordingly.

The conditional control-flow transfer instructions, like conditional jumps,
depending on CPU states, may or may not transfer control flows.
For conditional jumps, the CPU will test if certain condition flag 
(e.g., CF = 0, ZF =1) is met and jump to the certain branches respectively.
The symbolic engine will compute the flag and represent the flag 
in a symbol formula. Because we are running on a symbolic execution 
on a execution trace, we know which branch is executed.
If a conditional jump uses the CPU status flag, we will generate 
the constraint accordingly.

\begin{figure}[ht]
      \centering
      \includegraphics[width=\columnwidth]{./figures/secretCF.pdf}
      \caption{The workflow of \tool{}. \fixme{fix the caption, fix the drawing.} \fixme{duplicate label.}}
      \label{fig:Test-------------------}
  \end{figure}

For examples,

\begin{lstlisting}
...
0x0000e781      add dword [local_14h], 1
0x0000e785      cmp dword [local_14h], 4
0x0000e789      jne 0xe7df
0x0000e78b      mov dword [local_14h], 0
...
\end{lstlisting}

At the beginning of the instruction segment, the value at the 
address of local14h can be written as $F(\vec{K})$. At the address e785, 
the value will be updated with $F(\vec{K})+1$. Then the code compares 
the value with 4 and use the result as a conditional jump. 
Based on the result, we can have the following formula:

$$F(\vec{K}) + 1 = 4$$

The formula, together with the memory address (0xe789) is store
as a \textit{formula tuple (address, formula)}. 
Each formula tuple represents one leakage site.

\subsubsection{Secret-dependent data access}
Like input-dependent control-flow transfers, an adversary can also infer 
sensitive information from the data access pattern as well. 
We try to find this kind of leakages by checking 
every memory operand of the instruction. We generate the memory addressing 
formulas. As discussed before, every symbols in the formula is the input key. 
If the formula does not contain any symbols, the memory access is independent 
from the input sensitive information and will not leak any sensitive information 
according to our threat model. Otherwise, we will generate the constraint for
the memory addressing. We model the memory address with a symbolic formula 
$F(\vec{K})$. 
Because we also have the concrete value of the memory address $Addr1$. 
Inspired by the work from~\cite{203878}, the formula can be written as:

$$F(\vec{K}) >> L = Addr1 >> L$$

The $L$ represents the minimum memory address granularity that an attacker 
can observe. For example, Flush and Reload can distinguish between different
cache lines, which means the value of L is 6.

\subsubsection{Information Flow Check}
\tool{} is designed to help software developers find and understand the 
side-channel vulnerabilities. To ease the procedure of fixing the bug,
we also track the information flow for each byte of the input
buffer. 
The step can be seen as the mutiple-tag taint analysis.
With the help of the information from symbolic execution, we can implement
a relative simple but relatively precise information flow track.
At the begining of the analysis, \tool{} keep a track for each byte 
in the original buffer. When \tool{} symbolically executes each
instruction in the trace, it will check every value read from
registers or memory. If the value is concrete, it means the
instruction has nothing to do with the original buffer.
If the value is a formula, it means the orginal information
pass through the instruction. Since each byte in the sensitive
buffer is represented as a symbol with a unique ID, \tool{} can
know which byte in the origin buffer actually goes through the
instruction.


\subsection{Challenge II: How to Combine the Leakage Information from Multiple Leak Sites}
Real-world software can have various side-channel vulnerabilities. Those vulnerabilities 
may spread in the whole program. An adversary may exploit more than one side-channel vulnerabilities 
to gain more information~\cite{7163052, 191010}. In order to precisely quantify the
total information leakage, we need to know the relation of those leakage sites. 


\lstinputlisting[language=c, 
                 numbers=left,
                 numbersep=5pt,                   % how far the line-numbers are from the code
                 caption={Multiple leakages},
                 frame = single,
                 captionpos=b,
                 label={code::multiple},
                 basicstyle=\fontsize{7}{9}\selectfont\ttfamily]
                 {sample_code/motivation_multiple.c}

                

Consider the running example in ~\ref{code::multiple}, in which $k1$, $k2$ and $k3$ are
the sensitive key. The code has six different leakage. Leakage 1, 2, 3 are the secret-dependent
data accesses and leakage 4, 5, 6 are the secret-dependent control-flow transfers.  
The attacker can infer the last three digits of
$k1$, $k2$, $k3$ from leakage 1, 2, 3. So those leakages are independent. For leakage 1, 4, 6, however,
we have no idea about the total information leakage.


Suppose one program has two side-channel vulnerabilities A and B, which can leak $L_A$ and $L_B$ bits respectively
according to the definition~\ref{def}. 
Depending on the relation between A and B, the total leaked information $L_{\mathit{total}}$ will be:

\subsubsection{Independent Leakages}
If A and B are independent leakages, the total information leakage will be:
$$L_{\mathit{total}} = L_A + L_B $$

\subsubsection{Dependent Leakages}
If A and B are dependent leakages, the total information leakage will be:
$$\max{\{L_A, L_B\}}  \leq L_{\mathit{total}} < L_A + L_B$$

\subsubsection{Mutual Exclusive Leakages}
If A and B are mutual exclusive leakages, then only A or B can be observed for one fixed input.
$$L_{\mathit{total}} = 
\begin{cases}
L_A, & \text{only} ~ A \\
L_B, & \text{only} ~ B
\end{cases}$$

According to above definition, leakage 1, 2, 3 are independent leakages. Leakage 4, 5
are mutual exclusive leakages. 
For real-world applications, it is hard to estimate the total leaked information for the following reasons.
First, the real-world applications have more than thousands of lines of code. One leakage site leaks the temporary value. 
But the value contains some information about the original buffer. It is hard to know how the 
the sensitive value affects the temporary value. Second, some leakages sites may be
dependent. The occurrence of the first affects the occurrence of the second sites. We 
can't simply add them up. Third, leakage sites are in the different blocks of the 
control-flow graph, which means that only one of the two leakages site may be executed
during the exectution.

\vspace*{6pt}
\textbf{Our Solution to Challenge II:}
Given a program $P$ with $k$ as the sensitive input, 
we use $k_i$ to denote the sensitive information, where $i$ is the index of the byte in the original buffer.  
We can represent each temporal
values with a formula. There are two types of values in the formula: the concrete value and
the symbolic value. We use the runtime information to simplify the formula. In other words,
we only use symbolic values to represent the sensitive input. For other values that are
independent from the sensitive input, we use the concrete value from the runtime information. 

After that, we model each leakage sites as a math formulas.
The attacker can retrieve the sensitive information by observing the different patterns in 
control-flows and data access when the program process different sensitive information. 
We refer them as the secret-dependent control flow and secret-dependent data access accordingly.
For secret-dependent control transfers, we model the leakage using the path conditions that cause the control
transfer. For secret-dependent memory accesses, we use a symbolic formula $F(\vec{K})$ to
represent the memory address and check if different sensitive inputs can lead to different
memory accesses. As long as we model each leakage with a formula. We can regard multiple leakges as the conjunction of
those formulas. 

%% the algorithm

