\section{Scalable to Real-world Crypto Systems}

In the section, we present existing problems and our solutions
in applying the method above in real-world crypto systems. 

We use symbolic execution to get the function $f_i$, and count 
the number of items in $K^o$.
With the definition~\ref{def}, we can estimate the total information leakage.
However, some pre-experiments show that above approach suffers from the unbearable cost, 
which impede its usage
to detect and quantify side-channel leakages in real-world applications. 

We systematically analyze bottlenecks of the whole process. In general, the performance suffers
from the two following reasons. 
\begin{itemize}
    \item Symbolic Execution (Challenge a)
    \item Counting the number of items in $K^o$ (Challenge b)
\end{itemize}

Both symbolic execution and model counting are well-known for theirs
expensive performance cost, which limit their usage in real-world
crypto systems.

\subsection{Trace-oriented Symbolic Execution}
Symbolic execution interprets each instruction and update the memory cells and registers with a 
formula that captured the semantics of the execution. Unfortunately, the number of machine instructions 
are huge and the semantics of each instruction is complex. For example, the Intel Developer Manual~\cite{intelsys}
introduces more than 1000 different X86 instructions. It is tedious to manually implement the
rules for every instructions.

Therefore, existing binary analysis tools ~\cite{shoshitaishvili2016state, 10.1007/978-3-642-22110-1_37} 
will translate machine instructions into intermediate languages (IR). The IR typically has fewer 
instructions compared to the original machine instructions. The IR layer designs, which significantly
simplify the implementations, also introduce significant overhead as well~\cite{217563}.

\vspace*{6pt}
\textbf{Our Solution to Challenge a:}
We adopt the similar approach from~\cite{217563} and implement the symbolic execution 
directly on the top X86 instructions.

\subsection{Monte Carlo Sampling}
\label{MCreasons}
For an application with $m$ bytes secret, there are total $2^{8m}$ possible inputs. Of the
$2^{8m}$ possible inputs, we want to estimate the number of inputs that satisfy those formulas.
Then we can use the definition ~/ref{def} to calculate the information leakage.

A Monte Carlo method for approximating the number of $|K_o|$ is to pick up 
$M$ random values and check how many of them satisfy those constrains. If $l$ values
satisfy those constrains, then the approximate result is $\frac{l*2^{8m}}{M}$.

However, the number of satisfying values could be exponentially small. Consider the formula
$F={k_1} = 1\land{k_2} = 2\land{k_3} = 3\land{k_4} = 4$, $k_1$, $k_2$, $k_3$ and $k_4$ each represents
one byte in the orginal sensitive input, there is only one possible solution of $2^{32}$ possible
values, which requres exponentially many samples to get a tight bound. 
The naive Monte Carlo Method also suffers from the curse of dimensionality. For example, 
the libjpeg libraries can transfer the image from one format into another format. One image could
be 1kMB. If we take each byte in the original buffer as symbols, the formula can have at most
1024 symbols. 

\vspace*{6pt}
\textbf{Our Solution to Challenge b:}
We adopt Monte Carlo sampling to estimate the number of possible input
that satisfies the logic formula groups. The key idea is that we have one group of input that satisfies
the logic formula constrains.  We will
introduce the method in the following subsection.
