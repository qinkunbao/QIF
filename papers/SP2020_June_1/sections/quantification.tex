
\section{Information Leakage Quantification}
 
\fixme{Section (II.B), this subsection: Clarify mutual information, min-entropy, 
and maximal leakage. How many types? maybe use subsubsection}

Given an event $e$ which occurs with the probability $p(e)$, if the event $e$ happens, 
then we receive
\begin{displaymath}
    I = - \log_2p(e)
\end{displaymath}
bits of information by knowing the event $e$.
Considering a char variable $a$ with one byte storage size in a C program, its value 
ranges from 0 to 255.  Assume
 \textit{a} has the uniform distribution. If at one time we observe that $a$
equals $1$, the probability of this observation is $\frac{1}{256}$. So the information we get is 
$-\log(\frac{1}{256}) = 8$ bits, which is exactly the size of the char variable in the C program.

Existing works on information leakage quantification uses Shannon entropy.
min-entropy \cite{10.1007/978-3-642-00596-1_21} and max-entropy.
In these frameworks, the input sensitive
information $K$ is viewed as a random variable. 

Let $k_i$ be one of the possible
value of $K$. The Shannon entropy $H(K)$ is defined as
\begin{displaymath}
    H(K) = - \sum_{k_i {\in} K}P(k_i)\log_2P(k_i)
\end{displaymath}

The Shannon entropy can be used to quantify the initial uncertainty about the sensitive
information. Suppose a program with some
sensitive input $K$, an adversary has some observations ($O$) through some side channel.
In this work, the observations are referred as the secret-dependent control-flows and
secret-dependent data-access patterns. \fixme{See the comment above, we need to explain these
  patterns before this point.} The conditional entropy $H(K|O)$ is
\begin{displaymath}
    H(K|O) = - \sum_{o_j {\in} O} {P(o_j) \sum_{k_i {\in} K}{P(k_i|o_j)\log_2P(k_i|o_j)}}
\end{displaymath}
Intuitively, the conditional information marks the uncertainty about $K$ after the adversary
has gained some observations ($O$). 

Some previous work uses the mutual information $I(K; O)$ to quantify the leakage which is defined 
as follows:
\begin{displaymath}
    \mathit{Leakage} = I(K;O) = \sum_{k_i {\in} K}{\sum_{o_j {\in} O}{P(k_i, o_j)\log_2\frac{P(k_i, o_j)}{P(k_i)P(o_j)}}}
\end{displaymath}
where $P(k_i, o_i)$ is the joint discrete distribution of $K$ and $O$.
Alternatively, the mutual information can also be computed with the following equation:
\begin{displaymath}
    \mathit{Leakage} = I(K;O) = H(K) - H(K|O) = H(O) - H(O|K)
\end{displaymath}

For a deterministic program, once the input $K$ is fixed, the program will have the same
control-flow transfers and data-access patterns. As a result, $P(k_i, o_j)$ will always
equals to 1 or 0. So the conditional entropy $H(O|K)$ will equal to zero. So the leakage defined
by the mutual information can be simplified into:
\begin{displaymath}
\label{mutual:information}
    \mathit{Leakage} = I(K;O) = H(O)
\end{displaymath}
In other words, once we know the distribution of those memory-access patterns. We can 
calculate how much information is actually leaked.

Another common method is based on the maximal leakage~\cite{10.1007/978-3-642-00596-1_21,10.1007/978-3-642-31424-7_40,182946}.
The formal information theory can prove that the maximal leakage is the upper bound of the mutual 
information (Channel Capacity).

\begin{displaymath}
    \mathit{Leakage} = \log(C(O))
\end{displaymath}
Here $C(O)$ represents the number of different observations that an attacker can have. 

%% put this example in next section
%%\section{Running Example}

%Now we provide a concrete example to show how the two types of quantification definition works and show that
%how our method is different.

%\vspace{3pt}
%\textbf{Maximal Leakage.} 
%Depending on the value of key, the code can run four different branches which corrosponding to 
%four different observations. Therefore, by the maximal leakage definition, the leakage equals to 
%$\log4 = 2$ bits.

%\vspace{3pt}
%\textbf{Mutual Information.}
%If the key satisfies the uniform distribution, the probability of the code runs each branch
%can be computed with the following result.  

%\begin{table}[h]
%\centering
%\resizebox{\columnwidth}{!}{
%\begin{tabular}{|c|c|c|c|c|}
%\hline
%Branch & A     & B      & C      & D       \\ \hline
%Possibility      & 1/256 & 64/256 & 64/256 & 127/256 \\ \hline
%\end{tabular}
%}
%\caption{The distribution of observations}
%\end{table}

%Therefore, the leakage equals to 
%$\frac{1}{256}\log\frac{1}{256} + \frac{1}{4}\log\frac{1}{4}*2 + \frac{127}{256}\log\frac{127}{256} = 1.7$ bits.

%\vspace{3pt}
%\textbf{\tool.}
%\fixme{What is out result here? Need explain}
